"""Core business logic for Kokoro TTS.

This module contains the main TTS engine and audio processing functionality,
separated from CLI-specific code to enable reuse in web UI and other interfaces.
"""

# Standard library imports
import os
import sys
import tempfile
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Optional, Callable, List, Dict, Any, Tuple, AsyncIterator, Iterator
from dataclasses import dataclass
from enum import Enum

# Third-party imports
import numpy as np
from ebooklib import epub, ITEM_DOCUMENT
from bs4 import BeautifulSoup
import soundfile as sf
from kokoro_onnx import Kokoro
import pymupdf4llm
import fitz

# Local imports
from kokoro_tts.config import PerformanceConfig

# Supported languages (hardcoded as kokoro-onnx 0.4.9+ doesn't expose get_languages())
SUPPORTED_LANGUAGES = [
    'en-us',   # American English
    'en-gb',   # British English
    'ja',      # Japanese
    'zh',      # Mandarin Chinese
    'ko',      # Korean
    'es',      # Spanish
    'fr',      # French
    'hi',      # Hindi
    'it',      # Italian
    'pt-br',   # Brazilian Portuguese
]

# Front matter keywords to skip when processing audiobooks
FRONT_MATTER_SKIP_KEYWORDS = [
    # Legal/Copyright
    'copyright', 'legal', 'license', 'isbn', 'edition notice',
    'publisher', 'publication', 'rights reserved', 'publishing information',

    # Navigation
    'table of contents', 'contents', 'toc',

    # Story metadata
    'acknowledgment', 'acknowledgments', 'dedication', 'dedications', 'epigraph',

    # Author/About
    'about the author', 'about author', 'author bio', 'author biography',
    'author note', 'by the author', 'also by',

    # Misc
    'title page', 'cover', 'half title', 'half-title',
]


def is_front_matter(title: str, order: int = 0, word_count: int = 0) -> bool:
    """Determine if a chapter is front matter that should be skipped.

    NOTE: Foreword, Preface, Introduction, and Prologue are considered
    part of the story and are NOT skipped.

    Args:
        title: Chapter title
        order: Chapter order (1-based)
        word_count: Number of words in chapter

    Returns:
        True if chapter should be skipped as front matter
    """
    title_lower = title.lower().strip()

    # Exact match with skip keywords
    if title_lower in FRONT_MATTER_SKIP_KEYWORDS:
        return True

    # Check if title contains skip keywords
    for keyword in FRONT_MATTER_SKIP_KEYWORDS:
        if keyword in title_lower:
            return True

    # Skip chapters that start with "by " (e.g., "By the same author")
    if title_lower.startswith('by '):
        return True

    # Skip very short chapters at the beginning with certain patterns
    if order <= 3 and word_count < 500:
        # Check for common patterns in short front matter
        if any(word in title_lower for word in ['copy', 'isbn', 'edition', 'publisher']):
            return True

    return False


def generate_audiobook_intro(metadata: dict) -> str:
    """Generate introduction text for audiobook.

    Args:
        metadata: Dictionary with book metadata (title, author, etc.)

    Returns:
        Introduction text, or empty string if no metadata available
    """
    title = metadata.get('title')
    author = metadata.get('author')

    # If we have both title and author
    if title and author:
        return f"This is {title}, written by {author}, narrated by Kokoro Text-to-Speech."

    # If we only have title
    elif title:
        return f"This is {title}, narrated by Kokoro Text-to-Speech."

    # If we only have author
    elif author:
        return f"This audiobook by {author} is narrated by Kokoro Text-to-Speech."

    # Fallback if no metadata
    else:
        return "Audiobook generated by Kokoro Text-to-Speech."


def extract_chapters_from_epub(epub_file, debug=False, skip_confirmation=False, skip_front_matter=False):
    """Extract chapters from epub file using ebooklib's metadata and TOC."""
    if not os.path.exists(epub_file):
        raise FileNotFoundError(f"EPUB file not found: {epub_file}")

    book = epub.read_epub(epub_file)
    chapters = []

    if debug:
        print("\nBook Metadata:")
        for key, value in book.metadata.items():
            print(f"  {key}: {value}")

        print("\nTable of Contents:")
        def print_toc(items, depth=0):
            for item in items:
                indent = "  " * depth
                if isinstance(item, tuple):
                    section_title, section_items = item
                    print(f"{indent}• Section: {section_title}")
                    print_toc(section_items, depth + 1)
                elif isinstance(item, epub.Link):
                    print(f"{indent}• {item.title} -> {item.href}")
        print_toc(book.toc)

    def get_chapter_content(soup, start_id, next_id=None):
        """Extract content between two fragment IDs"""
        content = []
        start_elem = soup.find(id=start_id)

        if not start_elem:
            return ""

        # Skip the heading itself if it's a heading
        if start_elem.name in ['h1', 'h2', 'h3', 'h4']:
            current = start_elem.find_next_sibling()
        else:
            current = start_elem

        while current:
            # Stop if we hit the next chapter
            if next_id and current.get('id') == next_id:
                break
            # Stop if we hit another chapter heading
            if current.name in ['h1', 'h2', 'h3'] and 'chapter' in current.get_text().lower():
                break
            content.append(current.get_text())
            current = current.find_next_sibling()

        return '\n'.join(content).strip()

    def process_toc_items(items, depth=0):
        processed = []
        for i, item in enumerate(items):
            if isinstance(item, tuple):
                section_title, section_items = item
                if debug:
                    print(f"{'  ' * depth}Processing section: {section_title}")
                processed.extend(process_toc_items(section_items, depth + 1))
            elif isinstance(item, epub.Link):
                if debug:
                    print(f"{'  ' * depth}Processing link: {item.title} -> {item.href}")

                # Skip if title suggests it's front matter (when enabled)
                if skip_front_matter and is_front_matter(item.title, order=len(processed) + 1):
                    if debug:
                        print(f"{'  ' * depth}Skipping front matter: {item.title}")
                    continue

                # Extract the file name and fragment from href
                href_parts = item.href.split('#')
                file_name = href_parts[0]
                fragment_id = href_parts[1] if len(href_parts) > 1 else None

                # Find the document
                doc = next((doc for doc in book.get_items_of_type(ITEM_DOCUMENT)
                          if doc.file_name.endswith(file_name)), None)

                if doc:
                    content = doc.get_content().decode('utf-8')
                    soup = BeautifulSoup(content, "html.parser")

                    # If no fragment ID, get whole document content
                    if not fragment_id:
                        text_content = soup.get_text().strip()
                    else:
                        # Get the next fragment ID if available
                        next_item = items[i + 1] if i + 1 < len(items) else None
                        next_fragment = None
                        if isinstance(next_item, epub.Link):
                            next_href_parts = next_item.href.split('#')
                            if next_href_parts[0] == file_name and len(next_href_parts) > 1:
                                next_fragment = next_href_parts[1]

                        # Extract content between fragments
                        text_content = get_chapter_content(soup, fragment_id, next_fragment)

                    # Clean up soup object to free memory
                    soup.decompose()
                    del soup, content

                    if text_content:
                        word_count = len(text_content.split())
                        order = len(processed) + 1

                        # Check again with word count for better detection
                        if skip_front_matter and is_front_matter(item.title, order=order, word_count=word_count):
                            if debug:
                                print(f"{'  ' * depth}Skipping short front matter: {item.title} ({word_count} words)")
                            continue

                        chapters.append({
                            'title': item.title,
                            'content': text_content,
                            'order': order
                        })
                        processed.append(item)
                        if debug:
                            print(f"{'  ' * depth}Added chapter: {item.title}")
                            print(f"{'  ' * depth}Content length: {len(text_content)} chars")
                            print(f"{'  ' * depth}Word count: {word_count}")
        return processed

    # Process the table of contents
    process_toc_items(book.toc)

    # If no chapters were found through TOC, try processing all documents
    if not chapters:
        if debug:
            print("\nNo chapters found in TOC, processing all documents...")

        # Get all document items sorted by file name
        docs = sorted(
            book.get_items_of_type(ITEM_DOCUMENT),
            key=lambda x: x.file_name
        )

        for doc in docs:
            if debug:
                print(f"Processing document: {doc.file_name}")

            content = doc.get_content().decode('utf-8')
            soup = BeautifulSoup(content, "html.parser")

            # Try to find chapter divisions
            chapter_divs = soup.find_all(['h1', 'h2', 'h3'], class_=lambda x: x and 'chapter' in x.lower())
            if not chapter_divs:
                chapter_divs = soup.find_all(lambda tag: tag.name in ['h1', 'h2', 'h3'] and
                                          ('chapter' in tag.get_text().lower() or
                                           'book' in tag.get_text().lower()))

            if chapter_divs:
                # Process each chapter division
                for i, div in enumerate(chapter_divs):
                    title = div.get_text().strip()

                    # Get content until next chapter heading or end
                    chapter_content = ''
                    for tag in div.find_next_siblings():
                        if tag.name in ['h1', 'h2', 'h3'] and (
                            'chapter' in tag.get_text().lower() or
                            'book' in tag.get_text().lower()):
                            break
                        chapter_content += tag.get_text() + '\n'

                    if chapter_content.strip():
                        chapters.append({
                            'title': title,
                            'content': chapter_content.strip(),
                            'order': len(chapters) + 1
                        })
                        if debug:
                            print(f"Added chapter: {title}")
            else:
                # No chapter divisions found, treat whole document as one chapter
                text_content = soup.get_text().strip()
                if text_content:
                    # Try to find a title
                    title_tag = soup.find(['h1', 'h2', 'title'])
                    title = title_tag.get_text().strip() if title_tag else f"Chapter {len(chapters) + 1}"

                    word_count = len(text_content.split())
                    order = len(chapters) + 1

                    # Skip front matter if enabled
                    if not (skip_front_matter and is_front_matter(title, order=order, word_count=word_count)):
                        chapters.append({
                            'title': title,
                            'content': text_content,
                            'order': order
                        })
                        if debug:
                            print(f"Added chapter: {title}")

            # Clean up soup object to free memory after processing each document
            soup.decompose()
            del soup, content

    # Print summary
    if chapters:
        print("\nSuccessfully extracted {} chapters:".format(len(chapters)))
        for chapter in chapters:
            print(f"  {chapter['order']}. {chapter['title']}")

        total_words = sum(len(chapter['content'].split()) for chapter in chapters)
        print("\nBook Summary:")
        print(f"Total Chapters: {len(chapters)}")
        print(f"Total Words: {total_words:,}")
        print(f"Total Duration: {total_words / 150:.1f} minutes")

        if debug:
            print("\nDetailed Chapter List:")
            for chapter in chapters:
                word_count = len(chapter['content'].split())
                print(f"  • {chapter['title']}")
                print(f"    Words: {word_count:,}")
                print(f"    Duration: {word_count / 150:.1f} minutes")
    else:
        print("\nWarning: No chapters were extracted!")
        if debug:
            print("\nAvailable documents:")
            for doc in book.get_items_of_type(ITEM_DOCUMENT):
                print(f"  • {doc.file_name}")

    return chapters


class PdfParser:
    """Parser for extracting chapters from PDF files.

    Attempts to extract chapters first from table of contents,
    then falls back to markdown-based extraction if TOC fails.
    """

    def __init__(self, pdf_path: str, debug: bool = False, min_chapter_length: int = 50, skip_confirmation: bool = False):
        """Initialize PDF parser.

        Args:
            pdf_path: Path to PDF file
            debug: Enable debug logging
            min_chapter_length: Minimum text length to consider as chapter
            skip_confirmation: Skip user confirmation prompt
        """
        self.pdf_path = pdf_path
        self.chapters = []
        self.debug = debug
        self.min_chapter_length = min_chapter_length
        self.skip_confirmation = skip_confirmation

        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDF file not found: {pdf_path}")

    def get_chapters(self):
        """Extract chapters from PDF file.

        Returns:
            List of chapter dictionaries with title, content and order.
        """
        if self.debug:
            print("\nDEBUG: Starting chapter extraction...")
            print(f"DEBUG: PDF file: {self.pdf_path}")
            print(f"DEBUG: Min chapter length: {self.min_chapter_length}")

        # Try TOC extraction first
        if self.get_chapters_from_toc():
            if self.debug:
                print(f"\nDEBUG: Successfully extracted {len(self.chapters)} chapters from TOC")
            return self.chapters

        # Fall back to markdown extraction
        if self.debug:
            print("\nDEBUG: TOC extraction failed, trying markdown conversion...")

        self.chapters = self.get_chapters_from_markdown()

        if self.debug:
            print(f"\nDEBUG: Markdown extraction complete")
            print(f"DEBUG: Found {len(self.chapters)} chapters")

        return self.chapters

    def get_chapters_from_toc(self):
        """Extract chapters using PDF table of contents.

        Returns:
            bool: True if chapters were found, False otherwise
        """
        doc = None
        try:
            doc = fitz.open(self.pdf_path)
            toc = doc.get_toc()

            if not toc:
                if self.debug:
                    print("\nDEBUG: No table of contents found")
                return False

            # Print TOC structure
            print("\nTable of Contents:")
            for level, title, page in toc:
                title = self._clean_title(title)
                indent = "  " * (level - 1)
                print(f"{indent}{'•' if level > 1 else '>'} {title} (page {page})")

            if self.debug:
                print(f"\nDEBUG: Found {len(toc)} TOC entries")

            # Get user confirmation (unless skipped)
            if not self.skip_confirmation:
                print("\nPress Enter to start processing, or Ctrl+C to cancel...")
                input()

            # Extract level 1 chapters, filtering out empty titles and duplicates
            seen_pages = set()
            chapter_markers = []

            for level, title, page in toc:
                if level == 1:
                    title = self._clean_title(title)
                    # Skip empty titles or titles that start on same page as previous entry
                    if title and page not in seen_pages:
                        chapter_markers.append((title, page))
                        seen_pages.add(page)

            if not chapter_markers:
                if self.debug:
                    print("\nDEBUG: No level 1 chapters found in TOC")
                return False

            if self.debug:
                print(f"\nDEBUG: Found {len(chapter_markers)} chapters:")
                for title, page in chapter_markers:
                    print(f"DEBUG: • {title} (page {page})")

            # Process each chapter
            for i, (title, start_page) in enumerate(chapter_markers):
                if self.debug:
                    print(f"\nDEBUG: Processing chapter {i+1}/{len(chapter_markers)}")
                    print(f"DEBUG: Title: {title}")
                    print(f"DEBUG: Start page: {start_page}")

                # Get chapter end page
                end_page = (chapter_markers[i + 1][1] - 1
                           if i < len(chapter_markers) - 1
                           else doc.page_count)

                # Extract chapter text
                chapter_text = self._extract_chapter_text(doc, start_page - 1, end_page)

                if len(chapter_text.strip()) > self.min_chapter_length:
                    self.chapters.append({
                        'title': title,
                        'content': chapter_text,
                        'order': i + 1
                    })
                    if self.debug:
                        print(f"DEBUG: Added chapter with {len(chapter_text.split())} words")

            return bool(self.chapters)

        except Exception as e:
            if self.debug:
                print(f"\nDEBUG: Error in TOC extraction: {str(e)}")
            return False

        finally:
            if doc:
                doc.close()

    def get_chapters_from_markdown(self):
        """Extract chapters by converting PDF to markdown.

        Returns:
            List of chapter dictionaries
        """
        chapters = []
        try:
            def progress(current, total):
                if self.debug:
                    print(f"\rConverting page {current}/{total}...", end="", flush=True)

            # Convert PDF to markdown
            md_text = pymupdf4llm.to_markdown(
                self.pdf_path,
                show_progress=True,
                progress_callback=progress
            )

            # Clean up markdown text
            md_text = self._clean_markdown(md_text)

            # Extract chapters
            current_chapter = None
            current_text = []
            chapter_count = 0

            for line in md_text.split('\n'):
                if line.startswith('#'):
                    # Save previous chapter if exists
                    if current_chapter and current_text:
                        chapter_text = ''.join(current_text)
                        if len(chapter_text.strip()) > self.min_chapter_length:
                            chapters.append({
                                'title': current_chapter,
                                'content': chapter_text,
                                'order': chapter_count
                            })

                    # Start new chapter
                    chapter_count += 1
                    current_chapter = f"Chapter {chapter_count}_{line.lstrip('#').strip()}"
                    current_text = []
                else:
                    if current_chapter is not None:
                        current_text.append(line + '\n')

            # Add final chapter
            if current_chapter and current_text:
                chapter_text = ''.join(current_text)
                if len(chapter_text.strip()) > self.min_chapter_length:
                    chapters.append({
                        'title': current_chapter,
                        'content': chapter_text,
                        'order': chapter_count
                    })

            return chapters

        except Exception as e:
            if self.debug:
                print(f"\nDEBUG: Error in markdown extraction: {str(e)}")
            return chapters

    def _clean_title(self, title: str) -> str:
        """Clean up chapter title text."""
        return title.strip().replace('\u200b', ' ')

    def _clean_markdown(self, text: str) -> str:
        """Clean up converted markdown text."""
        import re
        # Remove page markers
        text = text.replace('-', '')
        # Remove other unwanted characters
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def _extract_chapter_text(self, doc, start_page: int, end_page: int) -> str:
        """Extract text from PDF pages."""
        chapter_text = []
        for page_num in range(start_page, end_page):
            try:
                page = doc[page_num]
                text = page.get_text()
                chapter_text.append(text)
            except Exception as e:
                if self.debug:
                    print(f"\nDEBUG: Error extracting page {page_num}: {str(e)}")
                continue

        return '\n'.join(chapter_text)


class AudioFormat(Enum):
    """Supported audio output formats."""
    WAV = "wav"
    MP3 = "mp3"
    M4A = "m4a"


@dataclass
class Chapter:
    """Represents a chapter or section of text to be converted to speech."""
    title: str
    content: str
    order: int


@dataclass
class ProcessingOptions:
    """Options for text-to-speech processing."""
    voice: Optional[str] = None
    speed: float = 1.0
    lang: str = "en-us"
    format: AudioFormat = AudioFormat.WAV
    debug: bool = False


@dataclass
class AudiobookOptions:
    """Options for audiobook creation."""
    select_chapters: str = "all"
    keep_temp: bool = False
    temp_dir: Optional[str] = None
    no_metadata: bool = False
    no_chapters: bool = False
    cover_path: Optional[str] = None
    title: Optional[str] = None
    author: Optional[str] = None
    narrator: Optional[str] = None
    year: Optional[str] = None
    genre: Optional[str] = None
    description: Optional[str] = None
    skip_front_matter: bool = True
    intro_text: Optional[str] = None
    no_intro: bool = False


def validate_language(lang: str, kokoro=None) -> str:
    """Validate if the language is supported.

    Note: kokoro parameter is kept for backward compatibility but not used.
    Languages are now hardcoded as kokoro-onnx 0.4.9+ doesn't expose get_languages().

    Args:
        lang: Language code to validate
        kokoro: Optional kokoro instance (kept for backward compatibility, not used)

    Returns:
        Validated language code

    Raises:
        ValueError: If language is not supported
    """
    if lang not in SUPPORTED_LANGUAGES:
        supported_langs = ', '.join(sorted(SUPPORTED_LANGUAGES))
        raise ValueError(f"Unsupported language: {lang}\nSupported languages are: {supported_langs}")
    return lang


def chunk_text(text: str, initial_chunk_size: int = 1000) -> List[str]:
    """Split text into chunks at sentence boundaries with dynamic sizing.

    Args:
        text: Text to split into chunks
        initial_chunk_size: Target chunk size in characters (default: 1000)

    Returns:
        List of text chunks
    """
    sentences = text.replace('\n', ' ').split('.')
    chunks = []
    current_chunk = []
    current_size = 0
    chunk_size = initial_chunk_size

    for sentence in sentences:
        if not sentence.strip():
            continue  # Skip empty sentences

        sentence = sentence.strip() + '.'
        sentence_size = len(sentence)

        # If a single sentence is too long, split it into smaller pieces
        if sentence_size > chunk_size:
            words = sentence.split()
            current_piece = []
            current_piece_size = 0

            for word in words:
                word_size = len(word) + 1  # +1 for space
                if current_piece_size + word_size > chunk_size:
                    if current_piece:
                        chunks.append(' '.join(current_piece).strip() + '.')
                    current_piece = [word]
                    current_piece_size = word_size
                else:
                    current_piece.append(word)
                    current_piece_size += word_size

            if current_piece:
                chunks.append(' '.join(current_piece).strip() + '.')
            continue

        # Start new chunk if current one would be too large
        if current_size + sentence_size > chunk_size and current_chunk:
            chunks.append(' '.join(current_chunk))
            current_chunk = []
            current_size = 0

        current_chunk.append(sentence)
        current_size += sentence_size

    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks


def validate_voice(voice: str, kokoro) -> str | np.ndarray:
    """Validate if the voice is supported and handle voice blending.

    Format for blended voices: "voice1:weight,voice2:weight"
    Example: "af_sarah:60,am_adam:40" for 60-40 blend

    Args:
        voice: Voice name or blend specification
        kokoro: Kokoro instance for getting voices and voice styles

    Returns:
        Voice name string or blended voice style array

    Raises:
        ValueError: If voice is invalid or blending requirements not met
        SystemExit: On error getting supported voices
    """
    try:
        supported_voices = set(kokoro.get_voices())

        # Parse comma-separated voices for blend
        if ',' in voice:
            voices = []
            weights = []

            # Parse voice:weight pairs
            for pair in voice.split(','):
                if ':' in pair:
                    v, w = pair.strip().split(':')
                    voices.append(v.strip())
                    weights.append(float(w.strip()))
                else:
                    voices.append(pair.strip())
                    weights.append(50.0)  # Default to 50% if no weight specified

            if len(voices) != 2:
                raise ValueError("voice blending needs two comma separated voices")

            # Validate voice
            for v in voices:
                if v not in supported_voices:
                    supported_voices_list = ', '.join(sorted(supported_voices))
                    raise ValueError(f"Unsupported voice: {v}\nSupported voices are: {supported_voices_list}")

            # Normalize weights to sum to 100
            total = sum(weights)
            if total != 100:
                weights = [w * (100/total) for w in weights]

            # Create voice blend style
            style1 = kokoro.get_voice_style(voices[0])
            style2 = kokoro.get_voice_style(voices[1])
            blend = np.add(style1 * (weights[0]/100), style2 * (weights[1]/100))
            return blend

        # Single voice validation
        if voice not in supported_voices:
            supported_voices_list = ', '.join(sorted(supported_voices))
            raise ValueError(f"Unsupported voice: {voice}\nSupported voices are: {supported_voices_list}")
        return voice
    except Exception as e:
        print(f"Error getting supported voices: {e}")
        import sys
        sys.exit(1)


class KokoroEngine:
    """Main TTS engine for Kokoro text-to-speech conversion.

    This class provides high-level methods for converting text to speech,
    handling both simple text and complex documents (EPUB, PDF) with progress callbacks.
    """

    def __init__(
        self,
        model_path: str = "kokoro-v1.0.onnx",
        voices_path: str = "voices-v1.0.bin",
        progress_callback: Optional[Callable[[str, int, int], None]] = None,
        use_gpu: bool = False,
        provider: Optional[str] = None,
        performance_config: Optional[PerformanceConfig] = None
    ):
        """Initialize the Kokoro TTS engine.

        Args:
            model_path: Path to the Kokoro ONNX model file
            voices_path: Path to the voices binary file
            progress_callback: Optional callback for progress updates (message, current, total)
            use_gpu: If True, automatically select the best available GPU provider
            provider: Explicit provider name (e.g., 'CUDAExecutionProvider'). Takes precedence over use_gpu.
            performance_config: Optional performance configuration for parallel processing

        Raises:
            FileNotFoundError: If model or voices files don't exist
            Exception: If model fails to load
        """
        self.model_path = model_path
        self.voices_path = voices_path
        self.progress_callback = progress_callback
        self.kokoro: Optional[Kokoro] = None
        self.use_gpu = use_gpu
        self.provider = provider
        self.performance_config = performance_config or PerformanceConfig()

        # Async I/O support
        self._io_executor = None
        self._io_tasks = []

        # Check files exist
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")
        if not os.path.exists(voices_path):
            raise FileNotFoundError(f"Voices file not found: {voices_path}")

    def load_model(self):
        """Load the Kokoro model.

        Sets up GPU provider if requested before loading the model.

        Raises:
            Exception: If model fails to load
        """
        if self.kokoro is None:
            # Setup GPU provider if requested
            if self.provider:
                # Explicit provider specified
                os.environ['ONNX_PROVIDER'] = self.provider
            elif self.use_gpu:
                # Auto-select best GPU provider
                selected_provider = self._select_gpu_provider()
                if selected_provider:
                    os.environ['ONNX_PROVIDER'] = selected_provider
                else:
                    raise RuntimeError("GPU requested but no compatible GPU provider found")

            self.kokoro = Kokoro(self.model_path, self.voices_path)

    def _select_gpu_provider(self) -> Optional[str]:
        """Select the best available GPU provider.

        Returns:
            Provider name or None if no GPU available
        """
        try:
            import onnxruntime as ort
            available_providers = ort.get_available_providers()

            # Priority: CUDA > TensorRT > ROCm > CoreML
            # CUDA is prioritized as it's more commonly available than TensorRT
            # (TensorRT requires additional libraries beyond CUDA)
            if 'CUDAExecutionProvider' in available_providers:
                return 'CUDAExecutionProvider'
            elif 'TensorrtExecutionProvider' in available_providers:
                return 'TensorrtExecutionProvider'
            elif 'ROCMExecutionProvider' in available_providers:
                return 'ROCMExecutionProvider'
            elif 'CoreMLExecutionProvider' in available_providers:
                return 'CoreMLExecutionProvider'
        except Exception:
            pass
        return None

    def get_voices(self) -> List[str]:
        """Get list of available voices.

        Returns:
            List of voice names
        """
        if self.kokoro is None:
            self.load_model()
        return list(self.kokoro.get_voices())

    def validate_language(self, lang: str) -> str:
        """Validate if language is supported.

        Args:
            lang: Language code

        Returns:
            Validated language code

        Raises:
            ValueError: If language is not supported
        """
        return validate_language(lang)

    def validate_voice(self, voice: str) -> str | np.ndarray:
        """Validate voice and handle voice blending.

        Args:
            voice: Voice name or blend specification (e.g., "voice1:60,voice2:40")

        Returns:
            Voice name string or blended voice style array

        Raises:
            ValueError: If voice is invalid
        """
        if self.kokoro is None:
            self.load_model()
        return validate_voice(voice, self.kokoro)

    def chunk_text(self, text: str, chunk_size: int = 1000) -> List[str]:
        """Split text into chunks at sentence boundaries.

        Args:
            text: Text to chunk
            chunk_size: Target chunk size in characters

        Returns:
            List of text chunks
        """
        return chunk_text(text, chunk_size)

    def _process_chunk_wrapper(self, args):
        """Thread-safe wrapper for process_chunk.

        Args:
            args: Tuple of (chunk, voice, speed, lang, chunk_index, debug)

        Returns:
            Tuple of (chunk_index, samples, sample_rate, error_message)
        """
        chunk, voice, speed, lang, chunk_index, debug = args
        try:
            samples, sample_rate = self.process_chunk(
                chunk, voice, speed, lang, retry_count=0, debug=debug
            )
            return (chunk_index, samples, sample_rate, None)
        except Exception as e:
            return (chunk_index, None, None, str(e))

    def process_chunk(
        self,
        chunk: str,
        voice: str | np.ndarray,
        speed: float,
        lang: str,
        retry_count: int = 0,
        debug: bool = False
    ) -> Tuple[Optional[List[float]], Optional[int]]:
        """Process a single text chunk with automatic subdivision on errors.

        Args:
            chunk: Text to process
            voice: Voice name or blended style
            speed: Speech speed multiplier
            lang: Language code
            retry_count: Current retry attempt
            debug: Enable debug output

        Returns:
            Tuple of (samples, sample_rate) or (None, None) on error
        """
        if self.kokoro is None:
            self.load_model()

        try:
            samples, sample_rate = self.kokoro.create(
                chunk, voice=voice, speed=speed, lang=lang
            )
            return samples, sample_rate
        except Exception as e:
            error_msg = str(e)

            # Handle phoneme length error by subdividing
            if "index 510 is out of bounds" in error_msg:
                current_size = len(chunk)
                new_size = int(current_size * 0.6)

                # Split into smaller pieces
                words = chunk.split()
                pieces = []
                current_piece = []
                current_piece_size = 0

                for word in words:
                    word_size = len(word) + 1
                    if current_piece_size + word_size > new_size:
                        if current_piece:
                            pieces.append(' '.join(current_piece).strip())
                        current_piece = [word]
                        current_piece_size = word_size
                    else:
                        current_piece.append(word)
                        current_piece_size += word_size

                if current_piece:
                    pieces.append(' '.join(current_piece).strip())

                # Process each piece recursively
                all_samples = []
                last_sample_rate = None

                for piece in pieces:
                    samples, sr = self.process_chunk(
                        piece, voice, speed, lang, retry_count + 1, debug
                    )
                    if samples is not None:
                        all_samples.extend(samples)
                        last_sample_rate = sr

                if all_samples:
                    return all_samples, last_sample_rate

            return None, None

    def generate_audio(
        self,
        text: str,
        options: ProcessingOptions
    ) -> Tuple[Optional[np.ndarray], Optional[int]]:
        """Generate audio from text with optional parallel processing.

        Args:
            text: Text to convert
            options: Processing options

        Returns:
            Tuple of (audio samples, sample rate) or (None, None) on error
        """
        if self.kokoro is None:
            self.load_model()

        # Validate and prepare
        lang = self.validate_language(options.lang)
        voice = self.validate_voice(options.voice) if options.voice else "af_sarah"

        # Chunk the text
        chunks = self.chunk_text(text)
        total_chunks = len(chunks)

        # Choose processing path
        if self.performance_config.use_parallel and total_chunks > 1:
            return self._generate_audio_parallel(chunks, voice, options.speed, lang, options.debug)
        else:
            return self._generate_audio_sequential(chunks, voice, options.speed, lang, options.debug)

    def _generate_audio_sequential(
        self,
        chunks: List[str],
        voice: str | np.ndarray,
        speed: float,
        lang: str,
        debug: bool
    ) -> Tuple[Optional[np.ndarray], Optional[int]]:
        """Original sequential implementation for audio generation.

        Args:
            chunks: List of text chunks to process
            voice: Voice name or blended style
            speed: Speech speed multiplier
            lang: Language code
            debug: Enable debug output

        Returns:
            Tuple of (audio samples, sample rate) or (None, None) on error
        """
        all_samples = []
        sample_rate = None

        for i, chunk in enumerate(chunks, 1):
            if self.progress_callback:
                self.progress_callback(f"Processing chunk {i}/{len(chunks)}", i, len(chunks))

            samples, sr = self.process_chunk(
                chunk, voice, speed, lang, debug=debug
            )

            if samples is not None:
                all_samples.extend(samples)
                if sample_rate is None:
                    sample_rate = sr

        if self.progress_callback:
            self.progress_callback("Complete", len(chunks), len(chunks))

        if all_samples:
            return np.array(all_samples), sample_rate
        return None, None

    def _generate_audio_parallel(
        self,
        chunks: List[str],
        voice: str | np.ndarray,
        speed: float,
        lang: str,
        debug: bool
    ) -> Tuple[Optional[np.ndarray], Optional[int]]:
        """Parallel implementation for audio generation.

        Processes multiple chunks simultaneously using thread pool.

        Args:
            chunks: List of text chunks to process
            voice: Voice name or blended style
            speed: Speech speed multiplier
            lang: Language code
            debug: Enable debug output

        Returns:
            Tuple of (audio samples, sample rate) or (None, None) on error
        """
        all_samples = [None] * len(chunks)
        sample_rate = None
        completed = 0
        lock = threading.Lock()

        # Prepare args for parallel processing
        chunk_args = [
            (chunk, voice, speed, lang, i, debug)
            for i, chunk in enumerate(chunks)
        ]

        with ThreadPoolExecutor(max_workers=self.performance_config.max_workers) as executor:
            # Submit all chunks
            future_to_index = {
                executor.submit(self._process_chunk_wrapper, args): args[4]
                for args in chunk_args
            }

            # Process results as they complete
            for future in as_completed(future_to_index):
                chunk_index, samples, sr, error = future.result()

                if error:
                    raise RuntimeError(f"Chunk {chunk_index} failed: {error}")

                all_samples[chunk_index] = samples
                sample_rate = sr

                with lock:
                    completed += 1
                    if self.progress_callback:
                        self.progress_callback(
                            f"Processing chunks",
                            completed,
                            len(chunks)
                        )

        if self.progress_callback:
            self.progress_callback("Complete", len(chunks), len(chunks))

        # Flatten the list of samples
        flattened_samples = []
        for samples in all_samples:
            if samples is not None:
                flattened_samples.extend(samples)

        if flattened_samples:
            return np.array(flattened_samples), sample_rate
        return None, None

    def save_audio(
        self,
        samples: np.ndarray,
        sample_rate: int,
        output_path: str,
        format: AudioFormat = AudioFormat.WAV
    ):
        """Save audio samples to file.

        Args:
            samples: Audio sample data
            sample_rate: Sample rate in Hz
            output_path: Output file path
            format: Audio format
        """
        if format == AudioFormat.WAV:
            sf.write(output_path, samples, sample_rate)
        elif format in [AudioFormat.MP3, AudioFormat.M4A]:
            from pydub import AudioSegment

            # Write to temp WAV first
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                tmp_path = tmp.name
                sf.write(tmp_path, samples, sample_rate)

            try:
                audio = AudioSegment.from_wav(tmp_path)
                if format == AudioFormat.MP3:
                    audio.export(output_path, format='mp3', bitrate='128k')
                else:  # M4A
                    audio.export(output_path, format='mp4', codec='aac', bitrate='128k')
            finally:
                os.unlink(tmp_path)

    async def save_audio_async(
        self,
        samples: np.ndarray,
        sample_rate: int,
        output_path: str,
        format: AudioFormat = AudioFormat.WAV
    ) -> None:
        """Save audio samples to file asynchronously.

        Offloads file I/O to executor to avoid blocking TTS processing.

        Args:
            samples: Audio sample data
            sample_rate: Sample rate in Hz
            output_path: Output file path
            format: Audio format
        """
        loop = asyncio.get_event_loop()

        # Run synchronous save_audio in executor
        await loop.run_in_executor(
            self._get_io_executor(),
            self.save_audio,
            samples,
            sample_rate,
            output_path,
            format
        )

    def _get_io_executor(self) -> ThreadPoolExecutor:
        """Get or create I/O executor for async file operations.

        Returns:
            ThreadPoolExecutor for I/O operations
        """
        if self._io_executor is None:
            # Use a ThreadPoolExecutor for I/O operations
            # Separate from main processing executor
            self._io_executor = ThreadPoolExecutor(
                max_workers=self.performance_config.io_queue_size,
                thread_name_prefix="kokoro_io"
            )
        return self._io_executor

    def _cleanup_io_executor(self):
        """Shutdown I/O executor gracefully."""
        if self._io_executor:
            self._io_executor.shutdown(wait=True)
            self._io_executor = None

    def extract_chapters_from_epub(
        self,
        epub_path: str,
        debug: bool = False
    ) -> List[Chapter]:
        """Extract chapters from EPUB file.

        Args:
            epub_path: Path to EPUB file
            debug: Enable debug output

        Returns:
            List of Chapter objects
        """
        # Use local function (now defined earlier in this file)
        chapters_data = extract_chapters_from_epub(epub_path, debug)
        return [
            Chapter(
                title=ch['title'],
                content=ch['content'],
                order=ch['order']
            )
            for ch in chapters_data
        ]

    def extract_chapters_from_pdf(
        self,
        pdf_path: str,
        debug: bool = False
    ) -> List[Chapter]:
        """Extract chapters from PDF file.

        Args:
            pdf_path: Path to PDF file
            debug: Enable debug output

        Returns:
            List of Chapter objects
        """
        # Use PdfParser class defined earlier in this module
        parser = PdfParser(pdf_path, debug=debug, skip_confirmation=True)
        chapters_data = parser.get_chapters()
        return [
            Chapter(
                title=ch['title'],
                content=ch['content'],
                order=ch['order']
            )
            for ch in chapters_data
        ]

    def extract_chapters_streaming(self, file_path: str, debug: bool = False) -> Iterator[Chapter]:
        """Stream chapters one-at-a-time for memory efficiency.

        Yields chapters without loading entire document into memory.

        Args:
            file_path: Path to input file (epub, pdf, or txt)
            debug: Enable debug output

        Yields:
            Chapter objects one at a time
        """
        if file_path.endswith('.epub'):
            yield from self._extract_epub_streaming(file_path, debug)
        elif file_path.endswith('.pdf'):
            yield from self._extract_pdf_streaming(file_path, debug)
        else:
            # Text file
            yield from self._extract_text_streaming(file_path)

    def _extract_epub_streaming(self, epub_path: str, debug: bool = False) -> Iterator[Chapter]:
        """Stream EPUB chapters without loading all into memory.

        Args:
            epub_path: Path to EPUB file
            debug: Enable debug output

        Yields:
            Chapter objects one at a time
        """
        book = epub.read_epub(epub_path)
        toc = book.toc

        for order, item in enumerate(toc):
            try:
                # Get the linked document
                if hasattr(item, 'href'):
                    href = item.href.split('#')[0]
                    doc = book.get_item_with_href(href)

                    if doc:
                        content = doc.get_content()
                        soup = BeautifulSoup(content, 'html.parser')
                        text = soup.get_text()

                        # Clean up soup object immediately
                        soup.decompose()
                        del soup, content

                        yield Chapter(
                            title=item.title,
                            content=text,
                            order=order
                        )
            except Exception as e:
                if debug:
                    print(f"Error extracting chapter {order}: {e}")
                continue

    def _extract_pdf_streaming(self, pdf_path: str, debug: bool = False) -> Iterator[Chapter]:
        """Stream PDF chapters page-by-page.

        Args:
            pdf_path: Path to PDF file
            debug: Enable debug output

        Yields:
            Chapter objects one at a time
        """
        doc = fitz.open(pdf_path)
        toc = doc.get_toc()

        try:
            if toc:
                # Stream TOC-based chapters
                for order, (level, title, page) in enumerate(toc):
                    if level == 1:  # Only level 1 chapters
                        # Find next chapter's page
                        next_page = None
                        for i in range(order + 1, len(toc)):
                            if toc[i][0] == 1:
                                next_page = toc[i][2]
                                break
                        if next_page is None:
                            next_page = len(doc) + 1

                        # Extract text from chapter pages
                        text_parts = []
                        for page_num in range(page - 1, min(next_page - 1, len(doc))):
                            text_parts.append(doc[page_num].get_text())

                        yield Chapter(
                            title=title,
                            content='\n'.join(text_parts),
                            order=order
                        )
            else:
                # Stream page-by-page
                for page_num in range(len(doc)):
                    text = doc[page_num].get_text()
                    yield Chapter(
                        title=f"Page {page_num + 1}",
                        content=text,
                        order=page_num
                    )
        finally:
            doc.close()

    def _extract_text_streaming(self, text_path: str) -> Iterator[Chapter]:
        """Stream text file in chunks.

        Args:
            text_path: Path to text file

        Yields:
            Chapter objects one at a time
        """
        chunk_size = 50000  # 50KB chunks

        with open(text_path, 'r', encoding='utf-8') as f:
            chunk_num = 0
            while True:
                text = f.read(chunk_size)
                if not text:
                    break

                yield Chapter(
                    title=f"Chunk {chunk_num + 1}",
                    content=text,
                    order=chunk_num
                )
                chunk_num += 1

    def process_file(
        self,
        input_path: str,
        output_path: str,
        options: ProcessingOptions,
        progress_callback: Optional[Callable[[str, int, int], None]] = None
    ) -> bool:
        """Process an entire file (text, EPUB, or PDF) to audio.

        Args:
            input_path: Path to input file
            output_path: Path to output audio file
            options: Processing options
            progress_callback: Optional progress callback

        Returns:
            True if successful, False otherwise
        """
        # Store callback
        old_callback = self.progress_callback
        if progress_callback:
            self.progress_callback = progress_callback

        try:
            # Extract chapters based on file type
            if input_path.endswith('.epub'):
                chapters = self.extract_chapters_from_epub(input_path, options.debug)
            elif input_path.endswith('.pdf'):
                chapters = self.extract_chapters_from_pdf(input_path, options.debug)
            else:
                # Plain text file
                with open(input_path, 'r', encoding='utf-8') as f:
                    text = f.read()
                chapters = [Chapter(title="Chapter 1", content=text, order=1)]

            if not chapters:
                return False

            # Process all chapters
            all_samples = []
            sample_rate = None

            for chapter in chapters:
                samples, sr = self.generate_audio(chapter.content, options)
                if samples is not None:
                    all_samples.extend(samples)
                    if sample_rate is None:
                        sample_rate = sr

            if all_samples:
                self.save_audio(
                    np.array(all_samples),
                    sample_rate,
                    output_path,
                    options.format
                )
                return True

            return False

        finally:
            self.progress_callback = old_callback

    async def generate_audio_async(
        self,
        text: str,
        options: ProcessingOptions,
        progress_callback: Optional[Callable[[str, int, int], None]] = None
    ) -> Tuple[Optional[np.ndarray], Optional[int]]:
        """Generate audio from text asynchronously.

        Args:
            text: Text to convert
            options: Processing options
            progress_callback: Optional progress callback

        Returns:
            Tuple of (audio samples, sample rate) or (None, None) on error
        """
        # Run in executor to avoid blocking
        loop = asyncio.get_event_loop()

        # Store callback
        old_callback = self.progress_callback
        if progress_callback:
            self.progress_callback = progress_callback

        try:
            result = await loop.run_in_executor(
                None,
                self.generate_audio,
                text,
                options
            )
            return result
        finally:
            self.progress_callback = old_callback

    async def process_file_async(
        self,
        input_path: str,
        output_path: str,
        options: ProcessingOptions,
        progress_callback: Optional[Callable[[str, int, int], None]] = None
    ) -> bool:
        """Process a file asynchronously with optional streaming and async I/O.

        When use_memory_streaming is enabled, processes chapters one-at-a-time.
        When use_async_io is enabled, writes happen asynchronously.

        Args:
            input_path: Path to input file
            output_path: Path to output audio file
            options: Processing options
            progress_callback: Optional progress callback

        Returns:
            True if successful, False otherwise
        """
        # Use streaming mode if enabled
        if self.performance_config.use_memory_streaming:
            # Streaming mode requires output directory
            if not output_path or os.path.isfile(output_path):
                output_dir = os.path.dirname(output_path) if output_path else "output"
            else:
                output_dir = output_path

            return await self.process_file_streaming_async(
                input_path, output_dir, options, progress_callback
            )

        # Original non-streaming implementation
        loop = asyncio.get_event_loop()

        # Store callback
        old_callback = self.progress_callback
        if progress_callback:
            self.progress_callback = progress_callback

        try:
            result = await loop.run_in_executor(
                None,
                self.process_file,
                input_path,
                output_path,
                options,
                progress_callback
            )
            return result
        finally:
            self.progress_callback = old_callback

    async def process_file_streaming_async(
        self,
        input_path: str,
        output_dir: str,
        options: ProcessingOptions,
        progress_callback: Optional[Callable[[str, int, int], None]] = None
    ) -> bool:
        """Process file with memory streaming enabled.

        Processes chapters one-at-a-time to minimize memory usage.

        Args:
            input_path: Path to input file
            output_dir: Directory for output files
            options: Processing options
            progress_callback: Optional progress callback

        Returns:
            True if successful, False otherwise
        """
        os.makedirs(output_dir, exist_ok=True)

        # Store callback
        old_callback = self.progress_callback
        if progress_callback:
            self.progress_callback = progress_callback

        try:
            chapter_idx = 0

            # Stream chapters
            for chapter in self.extract_chapters_streaming(input_path, options.debug):
                if progress_callback:
                    progress_callback(f"Processing chapter: {chapter.title}", chapter_idx, -1)

                # Generate audio
                samples, sample_rate = await self.generate_audio_async(chapter.content, options)

                if samples is None:
                    continue

                # Sanitize chapter title for filename
                safe_title = "".join(c for c in chapter.title if c.isalnum() or c in (' ', '-', '_')).strip()
                safe_title = safe_title[:50]  # Limit length

                # Output path
                output_file = os.path.join(
                    output_dir,
                    f"chapter_{chapter_idx:03d}_{safe_title}.{options.format.value}"
                )

                # Write (async if enabled)
                if self.performance_config.use_async_io:
                    task = asyncio.create_task(
                        self.save_audio_async(samples, sample_rate, output_file, options.format)
                    )
                    self._io_tasks.append(task)
                else:
                    self.save_audio(samples, sample_rate, output_file, options.format)

                chapter_idx += 1

            # Wait for all writes
            if self.performance_config.use_async_io and self._io_tasks:
                if progress_callback:
                    progress_callback("Waiting for writes to complete...", chapter_idx, chapter_idx)
                await asyncio.gather(*self._io_tasks)
                self._io_tasks.clear()

            if progress_callback:
                progress_callback(f"Complete: {chapter_idx} chapters processed", chapter_idx, chapter_idx)

            return chapter_idx > 0

        finally:
            self.progress_callback = old_callback
            self._cleanup_io_executor()

    async def stream_audio_async(
        self,
        text: str,
        options: ProcessingOptions
    ) -> AsyncIterator[Tuple[np.ndarray, int]]:
        """Stream audio generation chunk by chunk.

        Args:
            text: Text to convert
            options: Processing options

        Yields:
            Tuples of (audio samples, sample rate) for each chunk
        """
        if self.kokoro is None:
            self.load_model()

        # Validate
        lang = self.validate_language(options.lang)
        voice = self.validate_voice(options.voice) if options.voice else "af_sarah"

        # Chunk text
        chunks = self.chunk_text(text)

        # Process chunks one at a time
        for i, chunk in enumerate(chunks, 1):
            if self.progress_callback:
                self.progress_callback("Streaming", i, len(chunks))

            # Use kokoro's stream API if available
            if hasattr(self.kokoro, 'create_stream'):
                async for samples, sample_rate in self.kokoro.create_stream(
                    chunk, voice=voice, speed=options.speed, lang=lang
                ):
                    yield np.array(samples), sample_rate
            else:
                # Fallback to regular generation
                loop = asyncio.get_event_loop()
                samples, sample_rate = await loop.run_in_executor(
                    None,
                    self.process_chunk,
                    chunk,
                    voice,
                    options.speed,
                    lang,
                    0,
                    options.debug
                )
                if samples is not None:
                    yield np.array(samples), sample_rate
