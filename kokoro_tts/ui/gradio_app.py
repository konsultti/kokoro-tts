"""Gradio web interface for Kokoro TTS.

This module provides a user-friendly web UI for text-to-speech conversion
with support for voice blending, file uploads, and real-time audio playback.
"""

import os
import tempfile
from typing import Optional, Tuple, List
import numpy as np

try:
    import gradio as gr
except ImportError:
    raise ImportError(
        "Gradio is required for the web UI. Install with: pip install 'kokoro-tts[ui]'"
    )

from kokoro_tts.core import (
    KokoroEngine,
    ProcessingOptions,
    AudioFormat,
    SUPPORTED_LANGUAGES
)

from kokoro_tts.jobs import (
    JobManager,
    JobStatus,
    AudiobookJob,
    BookMetadata
)


class KokoroUI:
    """Gradio UI wrapper for Kokoro TTS engine."""

    def __init__(
        self,
        model_path: str = "kokoro-v1.0.onnx",
        voices_path: str = "voices-v1.0.bin",
        use_gpu: bool = False
    ):
        """Initialize UI with model paths.

        Args:
            model_path: Path to Kokoro ONNX model
            voices_path: Path to voices binary file
            use_gpu: Enable GPU acceleration if available
        """
        self.model_path = model_path
        self.voices_path = voices_path
        self.use_gpu = use_gpu
        self.engine: Optional[KokoroEngine] = None
        self.voices_list: List[str] = []

        # Initialize job manager for background processing
        self.job_manager = JobManager()

    def initialize_engine(self) -> str:
        """Initialize the TTS engine and load voices.

        Returns:
            Status message
        """
        try:
            if self.engine is None:
                self.engine = KokoroEngine(
                    self.model_path,
                    self.voices_path,
                    use_gpu=self.use_gpu
                )
                self.engine.load_model()
                self.voices_list = sorted(self.engine.get_voices())

                gpu_status = " (GPU enabled)" if self.use_gpu else ""
                return f"‚úì Engine loaded successfully with {len(self.voices_list)} voices{gpu_status}"
        except Exception as e:
            return f"‚úó Error loading engine: {str(e)}"

    def generate_simple(
        self,
        text: str,
        voice: str,
        speed: float,
        language: str,
        progress=gr.Progress()
    ) -> Tuple[Optional[Tuple[int, np.ndarray]], str]:
        """Generate audio from text (Simple tab).

        Args:
            text: Input text
            voice: Selected voice
            speed: Speech speed
            language: Language code
            progress: Gradio progress tracker

        Returns:
            Tuple of (audio data, status message)
        """
        if not text.strip():
            return None, "‚ö† Please enter some text"

        try:
            # Initialize if needed
            if self.engine is None:
                status = self.initialize_engine()
                if "Error" in status:
                    return None, status

            # Create processing options
            options = ProcessingOptions(
                voice=voice,
                speed=speed,
                lang=language,
                format=AudioFormat.WAV
            )

            # Progress callback
            def update_progress(msg: str, current: int, total: int):
                progress((current, total), desc=msg)

            self.engine.progress_callback = update_progress

            # Generate audio
            progress(0, desc="Generating audio...")
            samples, sample_rate = self.engine.generate_audio(text, options)

            if samples is not None:
                # Gradio expects (sample_rate, samples) tuple
                return (sample_rate, samples), f"‚úì Generated {len(samples)/sample_rate:.1f}s of audio"
            else:
                return None, "‚úó Audio generation failed"

        except Exception as e:
            return None, f"‚úó Error: {str(e)}"

    def generate_from_file(
        self,
        file,
        voice: str,
        speed: float,
        language: str,
        output_format: str,
        progress=gr.Progress()
    ) -> Tuple[Optional[str], str]:
        """Generate audio from uploaded file.

        Args:
            file: Uploaded file object
            voice: Selected voice
            speed: Speech speed
            language: Language code
            output_format: Output audio format
            progress: Gradio progress tracker

        Returns:
            Tuple of (output file path, status message)
        """
        if file is None:
            return None, "‚ö† Please upload a file"

        try:
            # Initialize if needed
            if self.engine is None:
                status = self.initialize_engine()
                if "Error" in status:
                    return None, status

            # Get input file path
            input_path = file.name

            # Create output file
            file_ext = output_format.lower()
            output_file = tempfile.NamedTemporaryFile(
                delete=False,
                suffix=f'.{file_ext}'
            )
            output_path = output_file.name
            output_file.close()

            # Create processing options
            options = ProcessingOptions(
                voice=voice,
                speed=speed,
                lang=language,
                format=AudioFormat(file_ext)
            )

            # Progress callback
            def update_progress(msg: str, current: int, total: int):
                progress((current, total), desc=msg)

            # Process file
            progress(0, desc="Processing file...")
            success = self.engine.process_file(
                input_path,
                output_path,
                options,
                progress_callback=update_progress
            )

            if success:
                return output_path, f"‚úì File processed successfully"
            else:
                return None, "‚úó File processing failed"

        except Exception as e:
            return None, f"‚úó Error: {str(e)}"

    def preview_voice(
        self,
        voice: str,
        speed: float,
        language: str,
        progress=gr.Progress()
    ) -> Tuple[Optional[Tuple[int, np.ndarray]], str]:
        """Generate a preview with the selected voice.

        Args:
            voice: Voice to preview
            speed: Speech speed
            language: Language code
            progress: Gradio progress tracker

        Returns:
            Tuple of (audio data, status message)
        """
        preview_texts = {
            'en-us': "Hello! This is a preview of my voice. How do I sound?",
            'en-gb': "Hello! This is a preview of my voice. How do I sound?",
            'ja': "„Åì„Çì„Å´„Å°„ÅØÔºÅ„Åì„Çå„ÅØÁßÅ„ÅÆÂ£∞„ÅÆ„Éó„É¨„Éì„É•„Éº„Åß„Åô„ÄÇ",
            'zh': "‰Ω†Â•ΩÔºÅËøôÊòØÊàëÁöÑÂ£∞Èü≥È¢ÑËßà„ÄÇ",
            'ko': "ÏïàÎÖïÌïòÏÑ∏Ïöî! Ïù¥Í≤ÉÏùÄ Ï†ú Î™©ÏÜåÎ¶¨ ÎØ∏Î¶¨Î≥¥Í∏∞ÏûÖÎãàÎã§.",
            'es': "¬°Hola! Esta es una vista previa de mi voz.",
            'fr': "Bonjour! Ceci est un aper√ßu de ma voix.",
            'hi': "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Ø‡§π ‡§Æ‡•á‡§∞‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡§æ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§µ‡§≤‡•ã‡§ï‡§® ‡§π‡•à‡•§",
            'it': "Ciao! Questa √® un'anteprima della mia voce.",
            'pt-br': "Ol√°! Esta √© uma pr√©via da minha voz."
        }

        preview_text = preview_texts.get(language, preview_texts['en-us'])

        return self.generate_simple(preview_text, voice, speed, language, progress)

    def blend_voices(
        self,
        voice1: str,
        voice2: str,
        weight1: int,
        speed: float,
        language: str,
        progress=gr.Progress()
    ) -> Tuple[Optional[Tuple[int, np.ndarray]], str]:
        """Generate audio with blended voices.

        Args:
            voice1: First voice
            voice2: Second voice
            weight1: Weight for first voice (0-100)
            speed: Speech speed
            language: Language code
            progress: Gradio progress tracker

        Returns:
            Tuple of (audio data, status message)
        """
        weight2 = 100 - weight1
        blended_voice = f"{voice1}:{weight1},{voice2}:{weight2}"

        preview_text = f"This is a blend of {weight1}% {voice1} and {weight2}% {voice2}."

        return self.generate_simple(preview_text, blended_voice, speed, language, progress)

    def preview_audiobook_chapters(
        self,
        file,
        progress=gr.Progress()
    ) -> Tuple[dict, str, str]:
        """Preview chapters from uploaded book.

        Args:
            file: Uploaded EPUB or PDF file
            progress: Gradio progress tracker

        Returns:
            Tuple of (chapters dict, title, author)
        """
        if file is None:
            return {}, "", ""

        try:
            progress(0, desc="Loading book...")

            # Import required modules
            from kokoro_tts.audiobook import extract_epub_metadata, extract_pdf_metadata
            from kokoro_tts.core import extract_chapters_from_epub, PdfParser

            input_path = file.name

            # Extract metadata and chapters based on file type
            if input_path.endswith('.epub'):
                progress(0.3, desc="Extracting EPUB metadata...")
                metadata = extract_epub_metadata(input_path)

                progress(0.6, desc="Extracting chapters...")
                chapters_data = extract_chapters_from_epub(
                    input_path,
                    debug=False,
                    skip_confirmation=True,
                    skip_front_matter=False  # Show all chapters for preview
                )
            elif input_path.endswith('.pdf'):
                progress(0.3, desc="Extracting PDF metadata...")
                metadata = extract_pdf_metadata(input_path)

                progress(0.6, desc="Extracting chapters...")
                parser = PdfParser(input_path, debug=False, skip_confirmation=True)
                chapters_data = parser.get_chapters()
            else:
                return {"error": "Unsupported file type"}, "", ""

            # Format chapters for display
            progress(0.9, desc="Formatting chapters...")
            chapters_dict = {
                f"Chapter {i+1}": ch['title'][:80]  # Truncate long titles
                for i, ch in enumerate(chapters_data)
            }

            progress(1.0, desc="Complete!")

            return (
                chapters_dict,
                metadata.get('title', ''),
                metadata.get('author', '')
            )

        except Exception as e:
            return {"error": str(e)}, "", ""

    def generate_audiobook(
        self,
        file,
        voice: str,
        speed: float,
        language: str,
        title: str,
        author: str,
        narrator: str,
        year: str,
        genre: str,
        description: str,
        cover_file,
        select_chapters: str,
        skip_front_matter: bool,
        add_intro: bool,
        intro_text: str,
        keep_temp: bool,
        no_chapters: bool,
        progress=gr.Progress()
    ) -> Tuple[Optional[str], str, str]:
        """Generate audiobook from uploaded file.

        Args:
            file: Uploaded EPUB or PDF
            voice: Voice selection
            speed: Speech speed
            language: Language code
            title: Book title override
            author: Author override
            narrator: Narrator name
            year: Publication year
            genre: Book genre
            description: Book description
            cover_file: Custom cover image
            select_chapters: Chapter selection string
            skip_front_matter: Skip front matter chapters
            add_intro: Add introduction chapter
            intro_text: Custom intro text
            keep_temp: Keep temporary files
            no_chapters: Skip chapter markers
            progress: Gradio progress tracker

        Returns:
            Tuple of (output file path, info text, progress log)
        """
        if file is None:
            return None, "", "‚ö† Please upload a file"

        if not voice:
            return None, "", "‚ö† Please select a voice"

        temp_merged = None
        temp_dir_created = None

        try:
            # Initialize engine if needed
            if self.engine is None:
                status = self.initialize_engine()
                if "Error" in status:
                    return None, "", status

            progress(0.05, desc="[1/7] Initializing...")

            # Import required modules
            from kokoro_tts.audiobook import AudiobookCreator, calculate_chapter_timings, embed_audiobook_metadata
            from kokoro_tts.core import AudiobookOptions, Chapter
            from kokoro_tts.core import extract_chapters_from_epub, PdfParser, generate_audiobook_intro
            import shutil

            input_path = file.name

            # Create output file with original filename
            # Extract base name without extension
            import os
            base_name = os.path.splitext(os.path.basename(input_path))[0]
            output_filename = f"{base_name}.m4a"

            output_file = tempfile.NamedTemporaryFile(
                delete=False,
                suffix='.m4a',
                prefix=f"{base_name}_"
            )
            output_path = output_file.name
            output_file.close()

            # Create audiobook options
            audiobook_opts = AudiobookOptions(
                select_chapters=select_chapters or "all",
                keep_temp=keep_temp,
                no_metadata=False,  # Always embed metadata in UI
                no_chapters=no_chapters,
                skip_front_matter=skip_front_matter,
                intro_text=intro_text if intro_text else None,
                no_intro=not add_intro,
                cover_path=cover_file.name if cover_file else None,
                title=title if title else None,
                author=author if author else None,
                narrator=narrator if narrator else None,
                year=year if year else None,
                genre=genre if genre else None,
                description=description if description else None
            )

            # Progress tracking
            progress_log = []

            def log_progress(msg: str):
                progress_log.append(msg)

            def format_progress_log():
                """Format progress log with clear header and structure."""
                if not progress_log:
                    return "Starting audiobook creation..."
                return "PROGRESS LOG:\n" + "=" * 50 + "\n" + "\n".join(progress_log)

            # Initial yield - show we're starting
            # Output format: (file_download, info_panel, progress_log)
            yield None, "", format_progress_log()

            # Use AudiobookCreator context manager
            with AudiobookCreator(input_path, audiobook_opts) as creator:
                temp_dir_created = creator.temp_dir

                # Step 1: Extract metadata
                progress(0.1, desc="[1/7] Extracting metadata...")
                metadata = creator.extract_metadata()

                log_progress("‚úì [1/7] Metadata extracted")
                if metadata.get('title'):
                    log_progress(f"  - Title: \"{metadata['title']}\"")
                if metadata.get('author'):
                    log_progress(f"  - Author: \"{metadata['author']}\"")
                if metadata.get('cover'):
                    log_progress(f"  - Cover: Found ({len(metadata['cover'])} bytes)")

                yield None, "", format_progress_log()

                # Step 2: Extract and select chapters
                progress(0.15, desc="[2/7] Extracting chapters...")

                if input_path.endswith('.epub'):
                    all_chapters = extract_chapters_from_epub(
                        input_path,
                        debug=False,
                        skip_confirmation=True,
                        skip_front_matter=audiobook_opts.skip_front_matter
                    )
                else:  # PDF
                    parser = PdfParser(input_path, debug=False, skip_confirmation=True)
                    all_chapters = parser.get_chapters()

                if not all_chapters:
                    return None, "", "‚úó Error: No chapters found in file"

                # Convert to Chapter objects
                chapter_objects = [
                    Chapter(title=ch['title'], content=ch['content'], order=ch['order'])
                    for ch in all_chapters
                ]

                selected_chapters = creator.select_chapters_from_list(chapter_objects)

                log_progress(f"‚úì [2/7] Chapters extracted")
                log_progress(f"  - Selected {len(selected_chapters)} chapters")

                # Add introduction if requested
                if not audiobook_opts.no_intro:
                    if audiobook_opts.intro_text:
                        intro_content = audiobook_opts.intro_text
                    else:
                        intro_content = generate_audiobook_intro(metadata)

                    if intro_content:
                        intro_chapter = Chapter(title="Introduction", content=intro_content, order=0)
                        selected_chapters = [intro_chapter] + selected_chapters
                        log_progress("  - Added introduction chapter")

                yield None, "", format_progress_log()

                # Step 3: Generate audio for each chapter
                progress(0.20, desc="[3/7] Generating audio...")
                log_progress(f"‚úì [3/7] Generating audio ({len(selected_chapters)} chapters)")

                chapter_files = []
                chapter_titles = []

                for idx, chapter in enumerate(selected_chapters, 1):
                    log_progress(f"  - [{idx}/{len(selected_chapters)}] {chapter.title}")

                    # Generate audio for this chapter
                    chapter_file = os.path.join(temp_dir_created, f"chapter_{idx:03d}.m4a")

                    options = ProcessingOptions(
                        voice=voice,
                        speed=speed,
                        lang=language,
                        format=AudioFormat.M4A
                    )

                    samples, sr = self.engine.generate_audio(chapter.content, options)

                    if samples is not None:
                        self.engine.save_audio(samples, sr, chapter_file, AudioFormat.M4A)
                        chapter_files.append(chapter_file)
                        chapter_titles.append(chapter.title)
                    else:
                        log_progress(f"    ‚ö† Warning: No audio generated for chapter {idx}")

                    # Update progress bar and yield every chapter to keep displays in sync
                    chapter_progress = 0.20 + (0.50 * idx / len(selected_chapters))
                    progress(chapter_progress, desc=f"[3/7] Processing chapter {idx}/{len(selected_chapters)}: {chapter.title[:30]}...")
                    yield None, "", format_progress_log()

                if not chapter_files:
                    yield None, "", "‚úó Error: No audio generated"
                    return

                # Step 4: Merge chapters
                progress(0.72, desc="[4/7] Merging chapters...")
                log_progress(f"‚úì [4/7] Merging {len(chapter_files)} chapters")

                temp_merged = os.path.join(temp_dir_created, "_temp_merged.m4a")

                import subprocess
                with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                    filelist_path = f.name

                    # Create concat list
                    for chapter_file in chapter_files:
                        if os.path.exists(chapter_file):
                            abs_path = os.path.abspath(chapter_file)
                            escaped_path = abs_path.replace("'", "'\\''")
                            f.write(f"file '{escaped_path}'\n")

                try:
                    ffmpeg_cmd = [
                        'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
                        '-i', filelist_path,
                        '-c:a', 'aac', '-b:a', '128k',
                        temp_merged
                    ]

                    result = subprocess.run(
                        ffmpeg_cmd,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True
                    )

                    if result.returncode != 0:
                        raise Exception(f"FFmpeg failed: {result.stderr}")

                finally:
                    if os.path.exists(filelist_path):
                        os.unlink(filelist_path)

                yield None, "", format_progress_log()

                # Step 5: Embed metadata
                if not no_chapters:
                    progress(0.85, desc="[5/7] Embedding metadata...")
                    log_progress("‚úì [5/7] Embedding metadata and chapter markers")

                    # Calculate chapter timings
                    chapters_info = calculate_chapter_timings(
                        chapter_files,
                        chapter_titles
                    )

                    # Add narrator if not specified
                    if not metadata.get('narrator') and voice:
                        metadata['narrator'] = voice

                    # Embed metadata
                    try:
                        embed_audiobook_metadata(
                            temp_merged,
                            output_path,
                            metadata,
                            metadata.get('cover'),
                            chapters_info
                        )
                        log_progress(f"  - {len(chapters_info)} chapter markers added")
                        log_progress(f"  - Cover art embedded" if metadata.get('cover') else "  - No cover art")
                    except Exception as e:
                        log_progress(f"  ‚ö† Warning: Could not embed metadata: {e}")
                        log_progress(f"  - Copying file without metadata")
                        shutil.copy(temp_merged, output_path)
                else:
                    progress(0.85, desc="[5/7] Skipping metadata...")
                    log_progress("‚úì [5/7] Skipping metadata embedding (as requested)")
                    shutil.copy(temp_merged, output_path)

                yield None, "", format_progress_log()

            # Step 6: Calculate file info
            progress(0.95, desc="[6/7] Finalizing...")
            log_progress("‚úì [6/7] Calculating file information")

            from pydub import AudioSegment
            file_size = os.path.getsize(output_path) / (1024 * 1024)
            audio = AudioSegment.from_file(output_path, format='mp4')
            duration_sec = len(audio) / 1000.0
            hours = int(duration_sec // 3600)
            minutes = int((duration_sec % 3600) // 60)
            seconds = int(duration_sec % 60)

            yield None, "", format_progress_log()

            # Step 7: Create final file with proper name
            progress(1.0, desc="[7/7] Complete!")
            log_progress("‚úì [7/7] Audiobook creation complete!")
            log_progress(f"\nDuration: {hours}h {minutes}m {seconds}s")
            log_progress(f"Size: {file_size:.1f} MB")

            # Create a copy with the proper filename for download
            final_output_dir = tempfile.gettempdir()
            final_output_path = os.path.join(final_output_dir, output_filename)

            # Copy to final location with proper name
            shutil.copy(output_path, final_output_path)

            # Clean up the temp file with random name
            try:
                os.unlink(output_path)
            except:
                pass

            # Final info text for Audiobook Info panel
            info_text = f"""‚úì Audiobook created successfully!

Duration: {hours}h {minutes}m {seconds}s
Size: {file_size:.1f} MB
Format: M4A with AAC codec
Chapters: {len(chapter_files)} included
Voice: {voice}
Speed: {speed}x
"""

            # Final yield with completed results
            yield final_output_path, info_text, format_progress_log()

        except Exception as e:
            error_msg = f"‚úó Error: {str(e)}"
            progress_log.append(error_msg)
            yield None, "", format_progress_log()

        finally:
            # Clean up temporary files
            if temp_merged and os.path.exists(temp_merged):
                try:
                    os.unlink(temp_merged)
                except:
                    pass

            # AudiobookCreator context manager will handle its own cleanup
            # unless keep_temp is True

    def submit_audiobook_job(
        self,
        file,
        voice: str,
        speed: float,
        language: str,
        title: str,
        author: str,
        skip_front_matter: bool,
        add_intro: bool,
        intro_text: str
    ) -> Tuple[str, str]:
        """Submit audiobook generation as a background job.

        Args:
            file: Uploaded EPUB or PDF
            voice: Voice selection
            speed: Speech speed
            language: Language code
            title: Book title override
            author: Author override
            skip_front_matter: Skip front matter chapters
            add_intro: Add introduction chapter
            intro_text: Custom intro text

        Returns:
            Tuple of (job ID, status message)
        """
        if file is None:
            return "", "‚ö† Please upload a file"

        if not voice:
            return "", "‚ö† Please select a voice"

        try:
            # Create output file path
            base_name = os.path.splitext(os.path.basename(file.name))[0]
            output_dir = os.path.join(os.path.expanduser("~"), ".kokoro-tts", "audiobooks")
            os.makedirs(output_dir, exist_ok=True)
            output_file = os.path.join(output_dir, f"{base_name}.m4a")

            # Create metadata if provided
            metadata = None
            if title or author:
                metadata = BookMetadata(
                    title=title if title else None,
                    author=author if author else None
                )

            # Submit job
            job_id = self.job_manager.submit_job(
                input_file=file.name,
                output_file=output_file,
                voice=voice,
                speed=speed,
                lang=language,
                output_format="m4a",
                skip_front_matter=skip_front_matter,
                intro_text=intro_text if intro_text else None,
                no_intro=not add_intro,
                use_gpu=self.use_gpu,
                metadata=metadata
            )

            status_msg = f"""‚úì Job submitted successfully!

Job ID: {job_id}
Input: {os.path.basename(file.name)}
Output: {output_file}
Voice: {voice}
Speed: {speed}x

The audiobook will be processed in the background.
Switch to the "Job Status" tab to monitor progress.
"""

            return job_id, status_msg

        except Exception as e:
            return "", f"‚úó Error submitting job: {str(e)}"

    def get_all_jobs_display(self) -> Tuple[str, List[dict]]:
        """Get all jobs formatted for display.

        Returns:
            Tuple of (summary text, list of job dictionaries)
        """
        try:
            all_jobs = self.job_manager.get_all_jobs(limit=50)

            if not all_jobs:
                return "No jobs found", []

            # Group by status
            queued = [j for j in all_jobs if j.status == JobStatus.QUEUED]
            running = [j for j in all_jobs if j.status == JobStatus.RUNNING]
            completed = [j for j in all_jobs if j.status == JobStatus.COMPLETED]
            failed = [j for j in all_jobs if j.status == JobStatus.FAILED]
            cancelled = [j for j in all_jobs if j.status == JobStatus.CANCELLED]

            summary = f"""üìä Job Queue Summary

üîµ Queued: {len(queued)}
‚öôÔ∏è Running: {len(running)}
‚úÖ Completed: {len(completed)}
‚ùå Failed: {len(failed)}
üö´ Cancelled: {len(cancelled)}

Total: {len(all_jobs)} jobs
"""

            # Format jobs for display
            jobs_list = []
            for job in all_jobs:
                job_info = {
                    "Job ID": job.job_id[:8] + "...",
                    "Status": job.status.value.upper(),
                    "Input": os.path.basename(job.input_file_path),
                    "Progress": f"{job.progress.percentage:.1f}%",
                    "Created": self._format_timestamp(job.created_at)
                }
                jobs_list.append(job_info)

            return summary, jobs_list

        except Exception as e:
            return f"Error loading jobs: {str(e)}", []

    def get_job_details(self, job_id: str) -> str:
        """Get detailed information about a specific job.

        Args:
            job_id: Job ID to query

        Returns:
            Formatted job details
        """
        try:
            if not job_id or job_id == "No job selected":
                return "Please select a job"

            # Extract actual job ID (remove " ..." suffix if present)
            actual_id = job_id.split(" ")[0] if " " in job_id else job_id

            # Find job by partial ID match
            all_jobs = self.job_manager.get_all_jobs()
            job = None
            for j in all_jobs:
                if j.job_id.startswith(actual_id) or j.job_id == actual_id:
                    job = j
                    break

            if not job:
                return f"Job not found: {actual_id}"

            # Format details
            details = f"""üìã Job Details

Job ID: {job.job_id}
Status: {job.status.value.upper()}
Created: {self._format_timestamp(job.created_at)}

üìÅ Files:
  Input: {job.input_file_path}
  Output: {job.output_file_path}

‚öôÔ∏è Settings:
  Voice: {job.processing_options.get('voice', 'N/A')}
  Speed: {job.processing_options.get('speed', 1.0)}x
  Language: {job.processing_options.get('lang', 'N/A')}

üìä Progress:
  Percentage: {job.progress.percentage:.1f}%
  Chapters: {job.progress.completed_chapters}/{job.progress.total_chapters}
  Current: {job.progress.current_operation or 'N/A'}
"""

            if job.progress.eta_seconds:
                details += f"  ETA: {job.progress.format_eta()}\n"

            if job.status == JobStatus.COMPLETED:
                elapsed = job.get_elapsed_time()
                if elapsed:
                    details += f"\n‚è±Ô∏è Processing Time: {elapsed:.1f}s\n"
                if job.output_file_size:
                    size_mb = job.output_file_size / (1024 * 1024)
                    details += f"üíæ Output Size: {size_mb:.1f} MB\n"

            if job.status == JobStatus.FAILED and job.error_info:
                details += f"\n‚ùå Error:\n{job.error_info.error_message}\n"

            return details

        except Exception as e:
            return f"Error loading job details: {str(e)}"

    def cancel_job_action(self, job_id: str) -> str:
        """Cancel a job.

        Args:
            job_id: Job ID to cancel

        Returns:
            Status message
        """
        try:
            if not job_id or job_id == "No job selected":
                return "Please select a job"

            # Extract actual job ID
            actual_id = job_id.split(" ")[0] if " " in job_id else job_id

            # Find full job ID
            all_jobs = self.job_manager.get_all_jobs()
            full_id = None
            for j in all_jobs:
                if j.job_id.startswith(actual_id):
                    full_id = j.job_id
                    break

            if not full_id:
                return f"Job not found: {actual_id}"

            success = self.job_manager.cancel_job(full_id)

            if success:
                return f"‚úì Job cancelled: {actual_id}..."
            else:
                return f"‚ö† Cannot cancel job (may already be completed/cancelled)"

        except Exception as e:
            return f"Error cancelling job: {str(e)}"

    def resume_job_action(self, job_id: str) -> str:
        """Resume a failed job.

        Args:
            job_id: Job ID to resume

        Returns:
            Status message
        """
        try:
            if not job_id or job_id == "No job selected":
                return "Please select a job"

            # Extract actual job ID
            actual_id = job_id.split(" ")[0] if " " in job_id else job_id

            # Find full job ID
            all_jobs = self.job_manager.get_all_jobs()
            full_id = None
            for j in all_jobs:
                if j.job_id.startswith(actual_id):
                    full_id = j.job_id
                    break

            if not full_id:
                return f"Job not found: {actual_id}"

            success = self.job_manager.resume_job(full_id)

            if success:
                return f"‚úì Job resumed: {actual_id}..."
            else:
                return f"‚ö† Cannot resume job (may not have failed or no resume data)"

        except Exception as e:
            return f"Error resuming job: {str(e)}"

    @staticmethod
    def _format_timestamp(timestamp: float) -> str:
        """Format Unix timestamp as readable string."""
        import datetime
        dt = datetime.datetime.fromtimestamp(timestamp)
        return dt.strftime("%Y-%m-%d %H:%M:%S")


def create_ui(
    model_path: str = "kokoro-v1.0.onnx",
    voices_path: str = "voices-v1.0.bin",
    share: bool = False,
    use_gpu: bool = False
) -> gr.Blocks:
    """Create the Gradio UI interface.

    Args:
        model_path: Path to Kokoro model
        voices_path: Path to voices file
        share: Whether to create a public share link
        use_gpu: Enable GPU acceleration if available

    Returns:
        Gradio Blocks interface
    """
    ui = KokoroUI(model_path, voices_path, use_gpu=use_gpu)

    # Custom CSS for better styling
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
    }
    .tab-nav button {
        font-size: 16px !important;
    }
    """

    with gr.Blocks(
        title="Kokoro TTS",
        theme=gr.themes.Soft(),
        css=custom_css
    ) as demo:
        gr.Markdown(
            """
            # üéôÔ∏è Kokoro TTS - Text to Speech

            Convert text to natural-sounding speech with multiple voices and languages.
            Supports voice blending, EPUB/PDF processing, and more!
            """
        )

        # Status display
        status_box = gr.Textbox(
            label="Status",
            value="Ready. Engine will initialize on first use.",
            interactive=False
        )

        with gr.Tabs():
            # ===== TAB 1: Quick Generate =====
            with gr.Tab("Quick Generate"):
                gr.Markdown("### Generate speech from text")

                with gr.Row():
                    with gr.Column(scale=2):
                        simple_text = gr.Textbox(
                            label="Text to speak",
                            placeholder="Enter your text here...",
                            lines=8
                        )

                    with gr.Column(scale=1):
                        simple_voice = gr.Dropdown(
                            label="Voice",
                            choices=[],  # Will be populated on load
                            value=None,
                            interactive=True
                        )
                        simple_speed = gr.Slider(
                            minimum=0.5,
                            maximum=2.0,
                            value=1.0,
                            step=0.1,
                            label="Speed"
                        )
                        simple_lang = gr.Dropdown(
                            label="Language",
                            choices=SUPPORTED_LANGUAGES,
                            value="en-us"
                        )

                simple_generate_btn = gr.Button("üé§ Generate Speech", variant="primary", size="lg")

                simple_audio = gr.Audio(label="Generated Audio", type="numpy")
                simple_status = gr.Textbox(label="Result", interactive=False)

                simple_generate_btn.click(
                    fn=ui.generate_simple,
                    inputs=[simple_text, simple_voice, simple_speed, simple_lang],
                    outputs=[simple_audio, simple_status]
                )

            # ===== TAB 2: File Processing =====
            with gr.Tab("File Processing"):
                gr.Markdown("### Convert documents to audiobooks")
                gr.Markdown("Supports `.txt`, `.epub`, and `.pdf` files")

                with gr.Row():
                    with gr.Column(scale=2):
                        file_input = gr.File(
                            label="Upload File",
                            file_types=[".txt", ".epub", ".pdf"]
                        )

                    with gr.Column(scale=1):
                        file_voice = gr.Dropdown(
                            label="Voice",
                            choices=[],
                            value=None,
                            interactive=True
                        )
                        file_speed = gr.Slider(
                            minimum=0.5,
                            maximum=2.0,
                            value=1.0,
                            step=0.1,
                            label="Speed"
                        )
                        file_lang = gr.Dropdown(
                            label="Language",
                            choices=SUPPORTED_LANGUAGES,
                            value="en-us"
                        )
                        file_format = gr.Radio(
                            label="Output Format",
                            choices=["wav", "mp3", "m4a"],
                            value="wav"
                        )

                file_generate_btn = gr.Button("üìñ Process File", variant="primary", size="lg")

                file_output = gr.File(label="Download Audio")
                file_status = gr.Textbox(label="Result", interactive=False)

                file_generate_btn.click(
                    fn=ui.generate_from_file,
                    inputs=[file_input, file_voice, file_speed, file_lang, file_format],
                    outputs=[file_output, file_status]
                )

            # ===== TAB 3: Voice Lab =====
            with gr.Tab("Voice Lab"):
                gr.Markdown("### Experiment with voices")

                with gr.Tabs():
                    # Voice Preview
                    with gr.Tab("Voice Preview"):
                        gr.Markdown("Preview individual voices")

                        with gr.Row():
                            with gr.Column():
                                preview_voice = gr.Dropdown(
                                    label="Select Voice",
                                    choices=[],
                                    value=None,
                                    interactive=True
                                )
                                preview_speed = gr.Slider(
                                    minimum=0.5,
                                    maximum=2.0,
                                    value=1.0,
                                    step=0.1,
                                    label="Speed"
                                )
                                preview_lang = gr.Dropdown(
                                    label="Language",
                                    choices=SUPPORTED_LANGUAGES,
                                    value="en-us"
                                )

                        preview_btn = gr.Button("üéß Preview Voice", variant="primary")
                        preview_audio = gr.Audio(label="Voice Preview", type="numpy")
                        preview_status = gr.Textbox(label="Result", interactive=False)

                        preview_btn.click(
                            fn=ui.preview_voice,
                            inputs=[preview_voice, preview_speed, preview_lang],
                            outputs=[preview_audio, preview_status]
                        )

                    # Voice Blending
                    with gr.Tab("Voice Blending"):
                        gr.Markdown("Blend two voices together")

                        with gr.Row():
                            with gr.Column():
                                blend_voice1 = gr.Dropdown(
                                    label="Voice 1",
                                    choices=[],
                                    value=None,
                                    interactive=True
                                )
                                blend_voice2 = gr.Dropdown(
                                    label="Voice 2",
                                    choices=[],
                                    value=None,
                                    interactive=True
                                )
                                blend_weight = gr.Slider(
                                    minimum=0,
                                    maximum=100,
                                    value=50,
                                    step=5,
                                    label="Voice 1 Weight (%)",
                                    info="Voice 2 will be (100 - this value)%"
                                )
                                blend_speed = gr.Slider(
                                    minimum=0.5,
                                    maximum=2.0,
                                    value=1.0,
                                    step=0.1,
                                    label="Speed"
                                )
                                blend_lang = gr.Dropdown(
                                    label="Language",
                                    choices=SUPPORTED_LANGUAGES,
                                    value="en-us"
                                )

                        blend_btn = gr.Button("üé≠ Blend Voices", variant="primary")
                        blend_audio = gr.Audio(label="Blended Audio", type="numpy")
                        blend_status = gr.Textbox(label="Result", interactive=False)

                        blend_btn.click(
                            fn=ui.blend_voices,
                            inputs=[blend_voice1, blend_voice2, blend_weight, blend_speed, blend_lang],
                            outputs=[blend_audio, blend_status]
                        )

            # ===== TAB 4: Audiobook Creator =====
            with gr.Tab("Audiobook Creator"):
                gr.Markdown("""
                ### Create Professional Audiobooks
                Convert EPUB or PDF books into M4A audiobooks with metadata and chapter markers.
                Uses disk-based processing to handle large files efficiently.
                """)

                # File upload
                with gr.Row():
                    audiobook_file = gr.File(
                        label="üìö Upload Book (EPUB/PDF)",
                        file_types=[".epub", ".pdf"]
                    )

                # Basic settings
                with gr.Accordion("‚öôÔ∏è Basic Settings", open=True):
                    with gr.Row():
                        ab_voice = gr.Dropdown(
                            label="Voice",
                            choices=[],
                            value=None,
                            interactive=True
                        )
                        ab_speed = gr.Slider(
                            minimum=0.5,
                            maximum=2.0,
                            value=1.0,
                            step=0.1,
                            label="Speed"
                        )
                        ab_lang = gr.Dropdown(
                            label="Language",
                            choices=SUPPORTED_LANGUAGES,
                            value="en-us"
                        )

                # Metadata (auto-filled but editable)
                with gr.Accordion("üìù Metadata (auto-detected from file)", open=False):
                    ab_title = gr.Textbox(
                        label="Title",
                        placeholder="Auto-detected from file"
                    )
                    ab_author = gr.Textbox(
                        label="Author",
                        placeholder="Auto-detected from file"
                    )
                    ab_narrator = gr.Textbox(
                        label="Narrator",
                        placeholder="Defaults to voice name"
                    )
                    with gr.Row():
                        ab_year = gr.Textbox(
                            label="Year",
                            placeholder="e.g., 2024"
                        )
                        ab_genre = gr.Textbox(
                            label="Genre",
                            placeholder="e.g., Fiction"
                        )
                    ab_description = gr.Textbox(
                        label="Description",
                        lines=3,
                        placeholder="Auto-detected or leave empty"
                    )
                    ab_cover = gr.File(
                        label="Cover Image (optional override)",
                        file_types=[".jpg", ".jpeg", ".png"]
                    )

                # Chapter selection
                with gr.Accordion("üìñ Chapter Selection", open=False):
                    ab_preview_btn = gr.Button("Preview Chapters from File", variant="secondary")
                    ab_chapters_display = gr.JSON(
                        label="Available Chapters",
                        visible=False
                    )
                    ab_select_chapters = gr.Textbox(
                        label="Select Chapters",
                        value="all",
                        placeholder="Examples: all, 1-5, 1,3,5,7-10"
                    )

                # Advanced options
                with gr.Accordion("üîß Advanced Options", open=False):
                    ab_skip_front = gr.Checkbox(
                        label="Skip front matter (copyright, TOC, etc.)",
                        value=True
                    )
                    ab_add_intro = gr.Checkbox(
                        label="Add introduction chapter",
                        value=True
                    )
                    ab_intro_text = gr.Textbox(
                        label="Custom intro text (optional)",
                        lines=2,
                        placeholder="Leave empty for auto-generated intro"
                    )
                    with gr.Row():
                        ab_keep_temp = gr.Checkbox(
                            label="Keep temporary files",
                            value=False
                        )
                        ab_no_chapters = gr.Checkbox(
                            label="Skip chapter markers",
                            value=False
                        )

                # Generate buttons
                with gr.Row():
                    ab_generate_btn = gr.Button(
                        "üéß Create Audiobook (Blocking)",
                        variant="secondary",
                        size="lg"
                    )
                    ab_submit_job_btn = gr.Button(
                        "‚è≥ Submit as Background Job",
                        variant="primary",
                        size="lg"
                    )

                gr.Markdown("""
                **Note:**
                - **Background Job** (recommended): Submit to queue and process in background. You can close this tab.
                - **Blocking**: Process now and wait. UI will freeze until complete.
                """)

                # Output
                with gr.Row():
                    with gr.Column(scale=2):
                        ab_progress = gr.Textbox(
                            label="Progress Log",
                            lines=10,
                            interactive=False,
                            max_lines=20
                        )
                    with gr.Column(scale=1):
                        ab_info = gr.Textbox(
                            label="Audiobook Info",
                            lines=10,
                            interactive=False
                        )

                ab_output = gr.File(label="üì• Download Audiobook (M4A)")

                # Wire up events
                ab_preview_btn.click(
                    fn=ui.preview_audiobook_chapters,
                    inputs=[audiobook_file],
                    outputs=[ab_chapters_display, ab_title, ab_author]
                ).then(
                    lambda: gr.update(visible=True),
                    outputs=[ab_chapters_display]
                )

                ab_generate_btn.click(
                    fn=ui.generate_audiobook,
                    inputs=[
                        audiobook_file, ab_voice, ab_speed, ab_lang,
                        ab_title, ab_author, ab_narrator,
                        ab_year, ab_genre, ab_description, ab_cover,
                        ab_select_chapters, ab_skip_front, ab_add_intro,
                        ab_intro_text, ab_keep_temp, ab_no_chapters
                    ],
                    outputs=[ab_output, ab_info, ab_progress]
                )

                # Background job submission
                def submit_job_wrapper(file, voice, speed, lang, title, author, skip_front, add_intro, intro_text):
                    job_id, msg = ui.submit_audiobook_job(
                        file, voice, speed, lang, title, author,
                        skip_front, add_intro, intro_text
                    )
                    return None, msg, ""  # Clear output, show message in info, clear progress

                ab_submit_job_btn.click(
                    fn=submit_job_wrapper,
                    inputs=[
                        audiobook_file, ab_voice, ab_speed, ab_lang,
                        ab_title, ab_author,
                        ab_skip_front, ab_add_intro, ab_intro_text
                    ],
                    outputs=[ab_output, ab_info, ab_progress]
                )

            # ===== TAB 5: Job Status Dashboard =====
            with gr.Tab("Job Status"):
                gr.Markdown("""
                ### üìä Background Job Queue
                Monitor and manage audiobook generation jobs running in the background.
                Jobs continue processing even if you close this tab!
                """)

                with gr.Row():
                    refresh_btn = gr.Button("üîÑ Refresh Status", variant="secondary")
                    auto_refresh = gr.Checkbox(label="Auto-refresh (every 5s)", value=False)

                # Job summary
                job_summary = gr.Textbox(
                    label="Queue Summary",
                    lines=8,
                    interactive=False
                )

                # Job list
                job_list = gr.Dataframe(
                    headers=["Job ID", "Status", "Input", "Progress", "Created"],
                    label="All Jobs",
                    interactive=False,
                    wrap=True
                )

                # Job selection and actions
                with gr.Row():
                    selected_job = gr.Dropdown(
                        label="Select Job",
                        choices=["No job selected"],
                        value="No job selected",
                        interactive=True
                    )

                with gr.Row():
                    cancel_btn = gr.Button("üö´ Cancel Job", variant="stop", size="sm")
                    resume_btn = gr.Button("‚ñ∂Ô∏è Resume Job", variant="secondary", size="sm")

                # Job details
                job_details = gr.Textbox(
                    label="Job Details",
                    lines=15,
                    interactive=False
                )

                action_status = gr.Textbox(
                    label="Action Status",
                    lines=2,
                    interactive=False
                )

                # Wire up events
                def refresh_jobs_ui():
                    summary, jobs = ui.get_all_jobs_display()
                    job_ids = ["No job selected"] + [j["Job ID"] for j in jobs]
                    return summary, jobs, gr.update(choices=job_ids)

                refresh_btn.click(
                    fn=refresh_jobs_ui,
                    outputs=[job_summary, job_list, selected_job]
                )

                selected_job.change(
                    fn=ui.get_job_details,
                    inputs=[selected_job],
                    outputs=[job_details]
                )

                cancel_btn.click(
                    fn=ui.cancel_job_action,
                    inputs=[selected_job],
                    outputs=[action_status]
                ).then(
                    fn=refresh_jobs_ui,
                    outputs=[job_summary, job_list, selected_job]
                )

                resume_btn.click(
                    fn=ui.resume_job_action,
                    inputs=[selected_job],
                    outputs=[action_status]
                ).then(
                    fn=refresh_jobs_ui,
                    outputs=[job_summary, job_list, selected_job]
                )

                # Auto-refresh functionality
                def auto_refresh_jobs(auto_enabled):
                    import time
                    if auto_enabled:
                        time.sleep(5)
                        summary, jobs = ui.get_all_jobs_display()
                        job_ids = ["No job selected"] + [j["Job ID"] for j in jobs]
                        return summary, jobs, gr.update(choices=job_ids)
                    else:
                        return gr.update(), gr.update(), gr.update()

                # Initial load
                demo.load(
                    fn=refresh_jobs_ui,
                    outputs=[job_summary, job_list, selected_job]
                )

        # Load voices on startup
        def load_voices():
            status = ui.initialize_engine()
            voices = ui.voices_list if ui.voices_list else []
            default_voice = voices[0] if voices else None

            return (
                status,
                gr.update(choices=voices, value=default_voice),  # simple_voice
                gr.update(choices=voices, value=default_voice),  # file_voice
                gr.update(choices=voices, value=default_voice),  # preview_voice
                gr.update(choices=voices, value=default_voice),  # blend_voice1
                gr.update(choices=voices, value=default_voice if len(voices) < 2 else voices[1]),  # blend_voice2
                gr.update(choices=voices, value=default_voice),  # ab_voice
            )

        demo.load(
            fn=load_voices,
            outputs=[
                status_box,
                simple_voice,
                file_voice,
                preview_voice,
                blend_voice1,
                blend_voice2,
                ab_voice
            ]
        )

        gr.Markdown(
            """
            ---
            ### About

            **Kokoro TTS** - Ultra-realistic multilingual text-to-speech

            - üåç 10+ languages supported
            - üé≠ Voice blending capabilities
            - üìö EPUB & PDF support
            - ‚ö° Fast generation with ONNX

            [GitHub](https://github.com/nazdridoy/kokoro-tts) |
            [Documentation](https://github.com/nazdridoy/kokoro-tts#readme)
            """
        )

    return demo


def launch_ui(
    model_path: str = "kokoro-v1.0.onnx",
    voices_path: str = "voices-v1.0.bin",
    server_name: str = "127.0.0.1",
    server_port: int = 7860,
    share: bool = False,
    use_gpu: bool = False
):
    """Launch the Gradio web UI with background worker.

    This function can be called directly or used as a console entry point.
    When used as a console entry point (kokoro-tts-ui), it parses command-line
    arguments automatically.

    Args:
        model_path: Path to Kokoro model file
        voices_path: Path to voices file
        server_name: Server hostname
        server_port: Server port
        share: Create public share link
        use_gpu: Enable GPU acceleration if available
    """
    # If called as entry point, parse args
    import sys
    import atexit
    from kokoro_tts.jobs import start_worker_process

    if len(sys.argv) > 1:
        import argparse
        parser = argparse.ArgumentParser(description="Launch Kokoro TTS Web UI")
        parser.add_argument("--model", default=model_path, help="Path to model file")
        parser.add_argument("--voices", default=voices_path, help="Path to voices file")
        parser.add_argument("--server-name", default=server_name, help="Server hostname")
        parser.add_argument("--server-port", type=int, default=server_port, help="Server port")
        parser.add_argument("--share", action="store_true", help="Create public share link")
        parser.add_argument("--gpu", action="store_true", help="Enable GPU acceleration")
        args = parser.parse_args()

        model_path = args.model
        voices_path = args.voices
        server_name = args.server_name
        server_port = args.server_port
        share = args.share
        use_gpu = args.gpu

    # Start background worker process
    print("\n" + "="*60)
    print("Starting Kokoro TTS UI with Background Job Queue")
    print("="*60)
    print("Starting background worker process...")

    worker_process = start_worker_process(
        model_path=model_path,
        voices_path=voices_path
    )

    # Register cleanup function to terminate worker on exit
    def cleanup_worker():
        if worker_process.is_alive():
            print("\nShutting down background worker...")
            worker_process.terminate()
            worker_process.join(timeout=5)
            if worker_process.is_alive():
                worker_process.kill()
            print("Worker stopped.")

    atexit.register(cleanup_worker)

    print(f"Worker started (PID: {worker_process.pid})")
    print("\nJobs submitted via UI will be processed in the background.")
    print("You can close browser tabs and jobs will continue running.")
    print("="*60 + "\n")

    demo = create_ui(model_path, voices_path, share, use_gpu)

    try:
        demo.launch(
            server_name=server_name,
            server_port=server_port,
            share=share,
            show_error=True
        )
    except KeyboardInterrupt:
        print("\nShutting down gracefully...")
        cleanup_worker()
    finally:
        cleanup_worker()


if __name__ == "__main__":
    launch_ui()
